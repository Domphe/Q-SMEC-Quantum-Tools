{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4a5dcab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure WORKSPACE_ROOT resolves correctly in headless runs\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "def _compute_workspace_root():\n",
    "    env = os.getenv('WORKSPACE_ROOT')\n",
    "    if env:\n",
    "        return env\n",
    "    cwd = Path.cwd()\n",
    "    if cwd.name == 'airth_mining' and cwd.parent.name == 'Q-SMEC_Development_Environment':\n",
    "        return str(cwd.parent.parent)\n",
    "    return str(cwd)\n",
    "\n",
    "os.environ['WORKSPACE_ROOT'] = _compute_workspace_root()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8120f274",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "import os\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "\n",
    "WORKSPACE_ROOT = os.getenv('WORKSPACE_ROOT') or str(Path.cwd())\n",
    "AIRTH_DIR = Path(WORKSPACE_ROOT) / 'Q-SMEC_Development_Environment' / 'airth_mining'\n",
    "EXCEL_PATH = AIRTH_DIR / 'AIRTH_SENSOR_TEMPLATE.xlsx'\n",
    "EXCEL_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7d66af5",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert EXCEL_PATH.exists(), f'Excel file not found: {EXCEL_PATH}'\n",
    "schema_df = pd.read_excel(EXCEL_PATH, sheet_name='DataSchema')\n",
    "data_df = pd.read_excel(EXCEL_PATH, sheet_name='SampleData')\n",
    "kpis_df = pd.read_excel(EXCEL_PATH, sheet_name='KPIs')\n",
    "schema_df.head(), data_df.head(), kpis_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb673b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing: timestamp to datetime, numeric coercion, basic cleaning\n",
    "data = data_df.copy()\n",
    "if 'timestamp' in data.columns:\n",
    "    data['timestamp'] = pd.to_datetime(data['timestamp'], errors='coerce', utc=True)\n",
    "\n",
    "numeric_cols = ['value','temperature_c','humidity_pct','battery_pct','signal_strength_db','depth_m','lat','lon']\n",
    "for c in numeric_cols:\n",
    "    if c in data.columns:\n",
    "        data[c] = pd.to_numeric(data[c], errors='coerce')\n",
    "\n",
    "# Basic filters (example): drop rows without value or sensor_id\n",
    "data = data.dropna(subset=['value','sensor_id'])\n",
    "data.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eff1246c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# KPI recompute demo\n",
    "def recompute_kpis(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    rows = []\n",
    "    rows.append({'kpi':'records_total','value': int(len(df))})\n",
    "    if 'signal_strength_db' in df:\n",
    "        rows.append({'kpi':'avg_signal_db','value': float(df['signal_strength_db'].mean())})\n",
    "    if 'battery_pct' in df:\n",
    "        rows.append({'kpi':'median_battery_pct','value': float(df['battery_pct'].median())})\n",
    "    if 'status' in df:\n",
    "        rows.append({'kpi':'uptime_ok_pct','value': float((df['status']=='OK').mean()*100)})\n",
    "    # per reading_type\n",
    "    if 'reading_type' in df:\n",
    "        for t, v in df['reading_type'].value_counts(dropna=False).to_dict().items():\n",
    "            rows.append({'kpi': f'count_{t}', 'value': int(v)})\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "kpis_re = recompute_kpis(data)\n",
    "kpis_re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c85c692",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization stubs\n",
    "# 1) Time series for a single sensor and reading type\n",
    "sensor_example = data['sensor_id'].iloc[0] if len(data) else None\n",
    "rtype_example = data['reading_type'].iloc[0] if 'reading_type' in data and len(data) else None\n",
    "if sensor_example and rtype_example:\n",
    "    fig = px.line(data.query('sensor_id == @sensor_example and reading_type == @rtype_example').sort_values('timestamp'),\n",
    "                 x='timestamp', y='value', color='reading_type', title=f'Time Series â€” {sensor_example} / {rtype_example}')\n",
    "    fig.show()\n",
    "\n",
    "# 2) Distribution by reading_type\n",
    "if 'reading_type' in data:\n",
    "    fig2 = px.histogram(data, x='value', color='reading_type', nbins=40, title='Distribution by Reading Type')\n",
    "    fig2.show()\n",
    "\n",
    "# 3) Battery vs Signal scatter\n",
    "if {'battery_pct','signal_strength_db'}.issubset(data.columns):\n",
    "    fig3 = px.scatter(data, x='signal_strength_db', y='battery_pct', color='status',\n",
    "                      title='Battery vs Signal Strength (colored by status)')\n",
    "    fig3.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b99c1710",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple anomaly detection (z-score) per sensor+type\n",
    "data_z = data.copy()\n",
    "if not data_z.empty and {'sensor_id','reading_type','value'}.issubset(data_z.columns):\n",
    "    data_z['z'] = (data_z['value'] - data_z.groupby(['sensor_id','reading_type'])['value'].transform('mean')) / \\\n",
    "                    data_z.groupby(['sensor_id','reading_type'])['value'].transform('std')\n",
    "    data_z['anomaly'] = data_z['z'].abs() > 3\n",
    "    anomalies = data_z[data_z['anomaly']].sort_values('z', ascending=False)\n",
    "    anomalies[['timestamp','sensor_id','reading_type','value','z']].head(20)\n",
    "else:\n",
    "    print('Not enough columns for anomaly detection')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb47d41f",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "- Map AIRTH signals to domain-specific thresholds and business KPIs.\n",
    "- Integrate with hybrid AI+Quantum workflows (feature extraction, optimization, scheduling).\n",
    "- Add export routines for reports and dashboards."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81e4ab5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Assumptions and Domain KPIs from the Excel template\n",
    "assumptions_df = pd.read_excel(EXCEL_PATH, sheet_name='Assumptions')\n",
    "domain_kpis_seed = pd.read_excel(EXCEL_PATH, sheet_name='DomainKPIs') if 'DomainKPIs' in pd.ExcelFile(EXCEL_PATH).sheet_names else pd.DataFrame()\n",
    "assumptions_df.head(), domain_kpis_seed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b258663a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute domain-specific KPIs using assumptions\n",
    "A = {r['parameter']: r['value'] for _, r in assumptions_df.iterrows()} if not assumptions_df.empty else {}\n",
    "\n",
    "def compute_domain_kpis_local(df: pd.DataFrame, A: dict) -> pd.DataFrame:\n",
    "    rows = []\n",
    "    if df.empty:\n",
    "        return pd.DataFrame(rows)\n",
    "    rows.append({'kpi':'sensors_unique','value': int(df['sensor_id'].nunique())})\n",
    "    rows.append({'kpi':'sites_unique','value': int(df['site_id'].nunique())})\n",
    "    # uptime by sensor\n",
    "    up = df.groupby('sensor_id')['status'].apply(lambda s: float((s=='OK').mean()*100)).to_dict()\n",
    "    for s, v in up.items():\n",
    "        rows.append({'kpi': f'uptime_ok_pct__{s}', 'value': round(v,2)})\n",
    "    # thresholds\n",
    "    def count_exceed(sub, col, warn, alarm, higher_is_bad=True):\n",
    "        if sub.empty or col not in sub:\n",
    "            return 0, 0\n",
    "        if higher_is_bad:\n",
    "            return int((sub[col] >= warn).sum()), int((sub[col] >= alarm).sum())\n",
    "        else:\n",
    "            return int((sub[col] <= warn).sum()), int((sub[col] <= alarm).sum())\n",
    "    for rtype in ('THz_RCS','EM_Field','Vibration','Thermal'):\n",
    "        sub = df[df['reading_type']==rtype]\n",
    "        if rtype=='THz_RCS':\n",
    "            w,a_ = count_exceed(sub,'value',A.get('thz_rcs_warn_dbsm',-15),A.get('thz_rcs_alarm_dbsm',-10),True)\n",
    "        elif rtype=='EM_Field':\n",
    "            w,a_ = count_exceed(sub,'value',A.get('em_field_warn_mVpm',80),A.get('em_field_alarm_mVpm',100),True)\n",
    "        elif rtype=='Vibration':\n",
    "            w,a_ = count_exceed(sub,'value',A.get('vibration_warn_mms',4.0),A.get('vibration_alarm_mms',6.0),True)\n",
    "        else:\n",
    "            w,a_ = count_exceed(sub,'value',A.get('thermal_warn_c',40.0),A.get('thermal_alarm_c',45.0),True)\n",
    "        rows.append({'kpi': f'warn_count__{rtype}', 'value': w})\n",
    "        rows.append({'kpi': f'alarm_count__{rtype}', 'value': a_})\n",
    "    # battery / signal\n",
    "    if {'battery_pct','signal_strength_db'}.issubset(df.columns):\n",
    "        rows.append({'kpi':'low_battery_count','value': int((df['battery_pct'] <= A.get('battery_warn_pct',40)).sum())})\n",
    "        rows.append({'kpi':'weak_signal_count','value': int((df['signal_strength_db'] <= A.get('signal_warn_db',-85)).sum())})\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "computed_domain_kpis = compute_domain_kpis_local(data, A)\n",
    "computed_domain_kpis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "086064b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enhanced visualizations + export (HTML always; PNG if 'kaleido' installed)\n",
    "from pathlib import Path\n",
    "EXPORT_DIR = AIRTH_DIR / 'exports'\n",
    "EXPORT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Safe marker size derived from absolute values (avoid negative sizes)\n",
    "if 'value' in data:\n",
    "    data = data.copy()\n",
    "    data['_size'] = data['value'].abs().clip(lower=1.0)\n",
    "\n",
    "figs = []\n",
    "# Geo scatter if lat/lon available\n",
    "if {'lat','lon'}.issubset(data.columns):\n",
    "    fig_geo = px.scatter(data, x='lon', y='lat', color='reading_type', size='_size',\n",
    "                         title='Spatial Distribution of Readings (lat/lon)')\n",
    "    figs.append(('spatial_distribution', fig_geo))\n",
    "\n",
    "# Per-type distributions\n",
    "if 'reading_type' in data:\n",
    "    fig_dist = px.histogram(data, x='value', color='reading_type', nbins=50,\n",
    "                            title='Value Distributions by Reading Type', marginal='box')\n",
    "    figs.append(('value_distributions', fig_dist))\n",
    "\n",
    "# Battery vs Signal (trendline optional: requires statsmodels)\n",
    "if {'battery_pct','signal_strength_db'}.issubset(data.columns):\n",
    "    try:\n",
    "        import statsmodels.api\n",
    "        fig_bs = px.scatter(data, x='signal_strength_db', y='battery_pct', color='status',\n",
    "                            title='Battery vs Signal Strength', trendline='ols')\n",
    "    except ImportError:\n",
    "        fig_bs = px.scatter(data, x='signal_strength_db', y='battery_pct', color='status',\n",
    "                            title='Battery vs Signal Strength')\n",
    "    figs.append(('battery_vs_signal', fig_bs))\n",
    "\n",
    "# Save figures\n",
    "saved = []\n",
    "for name, fig in figs:\n",
    "    html_path = EXPORT_DIR / f'{name}.html'\n",
    "    fig.write_html(str(html_path))\n",
    "    saved.append(str(html_path))\n",
    "    try:\n",
    "        fig.write_image(str(EXPORT_DIR / f'{name}.png'))\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "saved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8c6a18a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export analytics report (Excel) with KPIs\n",
    "report_path = EXPORT_DIR / 'AIRTH_ANALYTICS_REPORT.xlsx'\n",
    "with pd.ExcelWriter(report_path, engine='openpyxl') as writer:\n",
    "    kpis_re.to_excel(writer, sheet_name='KPIs_Recomputed', index=False)\n",
    "    computed_domain_kpis.to_excel(writer, sheet_name='DomainKPIs', index=False)\n",
    "    data.head(2000).to_excel(writer, sheet_name='SampleData_Head', index=False)\n",
    "report_path"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
